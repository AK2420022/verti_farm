import configparser
import subprocess
import os
import random
import warnings
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
from easydict import EasyDict as edict
with warnings.catch_warnings():
    warnings.simplefilter("ignore", category=DeprecationWarning)
    from torch.utils.tensorboard import SummaryWriter
import torch
from mbpo import mbpo
class train_mbpo(object):
    def __init__(self):
        self.exp = edict()
        self.hypp = edict()
    def update_parameters(self, params):
        os.environ['SDL_VIDEODRIVER'] = 'dummy'
        os.environ['WANDB_NOTEBOOK_NAME'] = 'mbpo.py'

        warnings.filterwarnings("ignore", category=DeprecationWarning)

        plt.rcParams['figure.dpi'] = 100
        device = torch.device("cpu")
        
        exp = edict()
        exp.exp_name = 'mbpo'  # algorithm name, in this case it should be 'DQN'
        exp.env_id =  'HalfCheetah-v4'#name of the gym environment to be used in this experiment. Eg: Acrobot-v1, CartPole-v1, MountainCar-v0
        exp.device = device.type  # save the device type used to load tensors and perform tensor operations
        exp.max_episode_steps = 1000
        exp.set_random_seed = True  # set random seed for reproducibility of python, numpy and torch
        exp.seed = 2

        # name of the project in Weights & Biases (wandb) to which logs are patched. (only if wandb logging is enabled)
        # if the project does not exist in wandb, it will be created automatically
        wandb_prj_name = f"RL_{exp.env_id}"

        # name prefix of output files generated by the notebook
        exp.run_name = f"{exp.env_id}__{exp.exp_name}__{exp.seed}__{datetime.now().strftime('%y%m%d_%H%M%S')}"

        if exp.set_random_seed:
            random.seed(exp.seed)
            np.random.seed(exp.seed)
            torch.manual_seed(exp.seed)
            torch.backends.cudnn.deterministic = exp.set_random_seed

        # initialize the parameters
        hypp = edict()

        # flags for logging purposes
        exp.enable_wandb_logging = False
        exp.capture_video = True

        # flags to generate agent's average performance during training
        exp.eval_agent = True  # disable to speed up training
        exp.eval_count = 1000
        exp.eval_frequency = 500
        exp.exp_type = None

        # agent training specific parameters and hyperparameters
        hypp.total_timesteps = int(params["total_timesteps"])  # the training duration in number of time steps
        hypp.num_epochs = int(params["num_epochs"]) # total epochs
        hypp.epoch_length =int(params["epoch_length"]) # epoch length 
        hypp.gamma =float(params["gamma"])   # decay factor of future rewards
        hypp.tau = float(params["tau"] )
        hypp.log_entropy = float(params["log_entropy"] )
        #tweak in learning rates according to the learning rate according to the need
        #can I automate the learning rates???
        #should work >>
        #or automate runs in all
        hypp.hidden_layers_actor =int(params["hidden_layers_actor"]) 
        hypp.hidden_layers_critic = int(params["hidden_layers_critic"] )
        hypp.learning_rate = float(params["learning_rate"] )
        hypp.learning_rate_actor = float(params["learning_rate_actor"] )
        hypp.learning_rate_critic = float(params["learning_rate_critic"] )
        hypp.learning_rate_model = float(params["learning_rate_model"] )
        hypp.real_img_ratio = float(params["real_img_ratio"]) 
        hypp.display_evaluation = True #display video evaluation
        hypp.plot_training = True # plot training
        hypp.update_param_frequency = int(params["update_param_frequency"]) 
        hypp.model_train_frequency = int(params["model_train_frequency"] )
        hypp.rollout_schedule= [20, 150, 1, 5]
        hypp.action_prior = 'uniform'
        hypp.buffer_size = 100000  # the size of the replay memory buffer
        hypp.kstep =int(params["kstep"]) 
        hypp.num_rollouts = int(params["num_rollouts"]) 
        hypp.num_ensembles = int(params["num_ensembles"]) 
        hypp.hidden_dim = int(params["hidden_dim"]) 
        hypp.batch_size = int(params["batch_size"]) 
        hypp.start_learning = int(params["start_learning"] )
        hypp.train_frequency = int(params["train_frequency"]) 
        hypp.rollout_start = int(params["rollout_start"]) 
        hypp.max_ent_coef =float(params["max_ent_coef"]) 
        # reinit run_name 
        exp.run_name = f"{exp.env_id}__{exp.exp_name}__{exp.seed}__{datetime.now().strftime('%y%m%d_%H%M%S')}"
        exp.video_path = params["video_path"]
        self.exp = exp
        self.hypp = hypp
    def run_training(self):
        print("Running Simulation with Parameters")
        print("Experiment: ",self.exp)
        print("Hyper Parameters, ",self.hypp)
        ddp = mbpo(self.exp,self.hypp)

        ddp.train()

        return True
